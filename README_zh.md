# Useful Image Analysis Tool Integration (基于 SAM 和 PyQt)

这是一个使用 PyQt6 构建的图形用户界面 (GUI) 工具，目的是为了简化和加速科研或实验中常见的图像分析与处理任务，特别是针对需要批量处理大量图像（如显微照片、组织切片扫描图等）的场景。它可以帮你自动提取定量信息、比较图像特征或改善图像视觉效果。

## 主要功能

* **对比度增强**:
    * **作用**: 增大图像亮暗区域的差异，让图像细节更清楚。
    * **批量**: 可以一次性处理文件夹里所有的图片。
    * **调节**: 你可以自己设置增强的程度（大于1增强，小于1减弱）。

* **聚合分析**:
    * **“聚合度”是啥**: 我定义了一个叫“聚合度”的指标 (0-100)，用来衡量像素有多“暗”。简单说，**颜色越深，聚合度越高**。
        * **公式**: `聚合度 = 100 - (灰度值 / 255.0) * 100`
        * **例子**: 纯黑像素聚合度是 100，纯白是 0。
    * **快速评估**: 计算整张图或整个文件夹图片的**平均聚合度**，快速了解样本整体的“暗度”或“聚合水平”。

* **热力图生成**:
    * **作用**: 把每个像素的“聚合度”用不同颜色表示出来，生成一张彩色的图，直观展示聚合度在哪儿高、在哪儿低。
    * **怎么做**:
        1.  计算图片里每个像素的聚合度 (0-100)。
        2.  你设定一个感兴趣的聚合度**范围**（最低值 `Min Aggregate Threshold` 和最高值 `Max Aggregate Threshold`）。
        3.  **颜色规则**:
            * 聚合度**低于**最低值的像素：显示为**黑色** (背景)。
            * 聚合度**高于**最高值的像素：显示为**亮红色** (饱和)。
            * 聚合度在**范围内**的像素：颜色从**绿色** (接近最低值，聚合度低/较亮) 平滑过渡到 **黄色/橙色**，再到 **红色** (接近最高值，聚合度高/较暗)。
    * **目的**: 通过调整阈值，把注意力集中在感兴趣的聚合度区间，过滤掉背景或过曝区域，突出目标区域的分布和强度变化。

* **SAM 处理**:
    * **作用**: 把 Segment Anything Model (AI 自动分割) 和聚合度分析结合起来。它先自动找出图里的各个独立区域，然后用你设定的条件（分两步）筛选出你关心的目标，最后计算这些目标的指标（面积、强度、比率）并在图上标出来。
    * **模型**: 你需要自己提供预训练好的 SAM 模型文件 (`.pth`)。
    * **自动分割**: SAM 会自动把图像分割成很多独立的区域（生成掩码 masks）。
    * **两步筛选**:
        1.  **第一步：按区域整体属性筛选 (A/I/R Threshold)**:
            * 先算每个 SAM 找到的区域的**初始**面积、强度、比率。
            * 如果你勾选了 "Area" 或 "Intensity"，程序会检查这些初始值是否达到你设置的最小阈值 (`A/I/R Threshold`)。
            * 任何一个初始值**不达标**的区域，**直接淘汰**，不进入下一步。
        2.  **第二步：按像素聚合度筛选 (Min/Max Aggregate Threshold)**:
            * 对于**通过第一步**的区域，再检查它里面的**每一个像素**。
            * 只有聚合度落在你设定的 \[最低值, 最高值\] **区间内**的像素，才算这个区域的“有效像素”。
            * 如果一个区域通过了第一步，但在第二步检查后**一个“有效像素”都没有**，那这个区域**最终也不会被标记和计算**。
    * **最终计算和标注**:
        * 对于**两步都通过**的区域，程序**只用**第二步找到的“有效像素”来**重新计算**最终的：
            * **面积 (Area)**: 有效像素的数量。
            * **强度 (Intensity)**: 所有有效像素的聚合度加起来。
            * **比率 (Ratio)**: 强度 / 面积。
        * 程序会在输出图片上画出这个区域的**原始轮廓**，并用彩色文字标出**最终算出来**的 A/I/R 值。文字颜色与轮廓颜色相同，你可以用眼睛去挑选感兴趣的区域，并读出该区域的数值。
    * **详细参数调整 (SAM Auto Mask Generator Parameters)**: SAM 提供一些高级选项，让你可以微调它的工作方式。了解它们有助于解决特定问题：
        * **`points_per_side`** (每边点数, 默认 32): 想象在图上撒网格找物体，这个值是网格每边的点数。**值越高，网格越密**，更容易找到小东西，但也**更慢、更吃内存/显存**。反之则更快，但可能漏掉小的。
        * **`points_per_batch`** (每批点数, 默认 64): 决定了显卡 (GPU) 一次处理多少个网格点。**主要影响显存**。如果遇到 **"Out of Memory" 错误，就降低这个值** (比如 32 或 16)。如果显存很大，可以稍微提高试试能否加速。
        * **`pred_iou_thresh`** (预测 IoU 阈值, 默认 0.88): SAM 对自己找到的区域打的分数 (0-1)，表示它有多自信这个区域找对了。**值越高 (接近1)，要求越严**，结果噪点少，但可能把一些模糊的或者不太确定的目标漏掉。**值越低，要求越松**，可能找回一些目标，但也可能引入更多错误分割。
        * **`stability_score_thresh`** (稳定性阈值, 默认 0.95): 衡量找到的区域边界稳不稳固 (0-1)。稍微变动一下判断标准，形状会不会大变？**值越高，要求边界越稳定清晰**，结果更可靠，但可能丢掉边界模糊的目标。**值越低，能容忍更模糊的边界**，可能找回这类目标，但也可能得到形状奇怪的结果。
        * **`stability_score_offset`** (稳定性偏移, 默认 1.0): 计算稳定性分数时用的一个内部参数。
        * **`box_nms_thresh`** (包围盒 NMS 阈值, 默认 0.7): 防止同一个物体被画上好几个框。如果两个框重叠度高于这个值，就可能只保留一个。**值越低，去重越狠**，可能把靠太近 不同物体当成一个；**值越高，越容忍重叠**，可能同一个物体出好几个框。
        * **`crop_n_layers`** (裁剪层数, 默认 0): 处理超大图片的“切块”开关。**0 表示不切**，对整图处理。**设为 1 或更大**，会把大图切成很多重叠的小块分别处理再拼起来。优点是**能处理内存/显存装不下的大图**，缺点是**速度会慢很多很多**，而且拼接处可能不太自然。**只在处理超大图片遇到内存问题时，才考虑设为 1**。
        * **`crop_nms_thresh`** (裁剪 NMS 阈值, 默认 0.7): 切块模式下，合并小块结果时用的去重叠阈值。
        * **`crop_overlap_ratio`** (裁剪重叠率, 默认 \~0.341): 切块模式下，小块之间重叠部分的比例。
        * **`crop_n_points_downscale_factor`** (裁剪点数缩减因子, 默认 1): 切块模式下，每个小块里撒的点是否要稀疏一些。1 表示不稀疏。**值越大，小块处理越快，但精度可能下降。一般保持为 1**。
        * **`min_mask_region_area`** (最小掩码区域面积, 默认 0): 这是个**后期处理**步骤。设一个**大于 0** 的值（比如 50），程序会自动删掉所有面积小于这个像素数的、独立的、细小的分割结果。**非常适合用来自动清理背景上的小噪点**。设为 0 则保留所有结果。
        * **`output_mode`** (输出模式, 默认 `binary_mask`): 控制 SAM 输出掩码的内部数据格式。

* **批量处理与易用性**:
    * **文件夹处理**: 主要功能都支持一次处理整个文件夹的图片。
    * **图形界面**: 我用 PyQt6 做了个直观的界面，选文件、设参数、看日志、打开结果文件夹都方便。
    * **日志**: 界面右边会显示详细的操作日志和处理信息。
    * **结果输出**: 处理完后，会在你选的输入文件夹旁边自动创建一个新文件夹放结果，文件夹名字会包含参数信息，方便管理。

## 系统要求

* **Python**: 最好用 **Python 3.9 或更高版本** (我开发测试用的是 3.11.9)。
* **操作系统**: 推荐 Windows 10 或 11。
* **硬件**: 如果要用 SAM 处理，并且想快一点（用 GPU 加速），建议有 NVIDIA 显卡，至少是 GeForce RTX 3060 或差不多的水平。只用 CPU 也能跑，就是会慢很多。
* **需要装的库**:
    * `PyQt6`
    * `opencv-python`
    * `numpy`
    * `Pillow`
    * `torch`
    * `torchvision`
    * `segment-anything`
    * `tifffile` (**推荐装**: 支持 TIFF 图片格式)
    * `pycocotools` (**可选**: 如果不需要处理 RLE 格式掩码就不用装)

## 安装指南

**准备工作:**

* **装 Git:** 你得先装好 [Git](https://git-scm.com/downloads)，才能用 `git clone` 把代码下下来。
* **装 Python:** 确保你的 Python 版本符合要求 (推荐 3.9+)。命令行里敲 `python --version` 查一下。

**步骤:**

1.  **下载代码**: 打开命令行，运行：
    ```bash
    git clone [https://github.com/CUIAOYU/Useful-Image-Analysis-Tool-Integration.git](https://github.com/CUIAOYU/Useful-Image-Analysis-Tool-Integration.git)
    cd Useful-Image-Analysis-Tool-Integration
    ```

2.  **(推荐) 创建虚拟环境**: 为了不和别的项目搞混库版本，最好给这个项目单独创建一个虚拟环境：
    ```bash
    # 创建 (比如叫 venv)
    python -m venv venv

    # 激活
    # Windows (cmd/powershell):
    .\venv\Scripts\activate
    # macOS/Linux (bash/zsh):
    source venv/bin/activate
    ```
    *后面的 `pip install` 都要在**激活环境后**进行。*

3.  **安装依赖**: 用 pip 把需要的库装上。运行：
    ```bash
    pip install PyQt6 opencv-python numpy Pillow torch torchvision segment-anything tifffile pycocotools
    ```
    * **安装提示和常见问题**:
        * **PyTorch/Torchvision**: 这俩的安装比较讲究，跟你的系统、有没有 N 卡、CUDA 版本都有关。**强烈建议**先去 [PyTorch 官网](https://pytorch.org/)，根据你的环境（系统、包管理器、计算平台选 CUDA 或 CPU）找到**官方给的安装命令**，**单独先执行**这个命令装好 PyTorch 和 Torchvision。然后再运行上面的 `pip install ...` 命令装剩下的（可以去掉 torch 和 torchvision）。
        * **Pycocotools**: Windows 上装这个可能需要先装 Microsoft C++ Build Tools。如果报错，要么想办法解决编译环境，要么如果用不到 RLE 格式，干脆不装它（程序会给个警告但能运行）。
        * **Tifffile**: 不装的话，就读不了 `.tif` 或 `.tiff` 格式的图片。
        * **其他库报错**: 仔细看 pip 的报错信息，通常里面有线索。

4.  **(可选) 检查一下**: 装完后，试试运行主程序（看下面“如何使用”第 3 步），如果界面能成功打开，基本就说明装好了。

## SAM 模型设置 - 重要!

SAM 处理功能需要预训练的模型文件 (`.pth`)。**这些文件很大，代码仓库里不带，得你自己下载。**

1.  **下载模型**:
    * 去 Meta AI Research 的官方 SAM 仓库或者你信得过的其他地方下载模型文件。
    * 常见的模型有 `vit_h` (最大最准但也最慢)、`vit_l` (中等)、`vit_b` (最小最快但可能没那么准)。根据你的需求和电脑配置选一个。
    * **官方链接**: [SAM Model Checkpoints](https://github.com/facebookresearch/segment-anything#model-checkpoints)

2.  **放好模型**:
    * 下载后，把 `.pth` 文件存到你电脑上一个好找的地方。
    * 运行工具时，在 "SAM Processing" 标签页，点 "Select SAM Model File (.pth)" 按钮，告诉程序你把模型文件放哪儿了。

## 如何使用

1.  **准备**: 确保依赖库都装好了，SAM 模型也下载好了。
2.  **激活环境**: 如果用了虚拟环境，先激活。
3.  **运行**: 在项目文件夹根目录，打开命令行，运行主脚本：
    ```bash
    python 你的主脚本文件名.py
    # 比如: python main_gui.py (具体看你的文件名是啥)
    ```
4.  **界面**: 程序打开后，左边是控制区（选功能、选文件、调参数），右边是日志区（看运行信息和报错）。
5.  **选功能**: 点顶部的标签切换功能 (比如 "Contrast Enhancement", "SAM Processing")。
6.  **设置和运行**:
    * 点 "Select Input Folder" 选要处理的图片文件夹。
    * (用 SAM 的话) 点 "Select SAM Model File (.pth)" 选模型文件。
    * 仔细调整界面上的各种参数。
    * 点蓝色的处理按钮（比如 "Process All Images"）开始跑。通常要先选好文件夹和模型，按钮才能点。
7.  **看结果**:
    * 处理时留意右边日志区的输出。
    * 处理完日志区会有提示。
    * 点 "Open Output Folder" 按钮可以直接打开结果文件夹。结果文件夹会自动建在输入文件夹旁边，名字里会带参数信息。

## 如何贡献

非常欢迎各种形式的贡献！

* **提 Bug 或建议**: 发现问题或者有改进想法？请到 GitHub 的 [Issues](https://github.com/CUIAOYU/Useful-Image-Analysis-Tool-Integration/issues) 页面提出来。描述越详细越好，比如怎么复现、截图、你的系统和软件版本等等。
* **贡献代码**: 想直接改代码？欢迎！请走标准的 GitHub Fork & Pull Request 流程。最好是先开个 Issue 讨论一下你想做的改动。

## 报告问题

遇到 Bug 或有功能需求，请直接在仓库的 [Issues](https://github.com/CUIAOYU/Useful-Image-Analysis-Tool-Integration/issues) 页面开新的 Issue。

## 许可证

本项目使用 **MIT 许可证**。具体看 `LICENSE` 文件。
